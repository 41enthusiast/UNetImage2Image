diff --git a/config.py b/config.py
index b26f80d..67c3326 100644
--- a/config.py
+++ b/config.py
@@ -3,10 +3,10 @@ from typing import Optional
 
 @dataclass
 class DataConfig:
-    dataset_name: str = "art_dataset_v2"
-    dataset_path: str = "../art_painting_data"
+    dataset_name: str = "art_dataset_v1"
+    dataset_path: str = "../data/art_painting"
     img_size: int = 224
-    batch_size: int = 8
+    batch_size: int = 128
     num_workers: int = 8
     augment: bool = True
 
@@ -58,7 +58,7 @@ class ModelConfig_Swin:
 @dataclass
 class TrainConfig:
     lr: float = 1e-3
-    max_epochs: int = 10
+    max_epochs: int = 5000
     precision: int = 16          # AMP
     num_devices: int = 1
     accumulate_grad_batches: int = 1
diff --git a/requirements.txt b/requirements.txt
index 6b1921e..67d35d9 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -2,4 +2,6 @@ torchsummary
 torchvision
 matplotlib
 albumentations
-pytorch_lightning
\ No newline at end of file
+pytorch_lightning
+torchmetrics
+wandb
\ No newline at end of file
diff --git a/train.py b/train.py
index 4251070..91df0b4 100644
--- a/train.py
+++ b/train.py
@@ -21,6 +21,7 @@ class Img_2_Img(pl.LightningModule):
         super(Img_2_Img, self).__init__()
         self.model = model
         self.MSE = nn.MSELoss()
+        self.log_image_every_n_epochs = 10
 
     def forward(self, x):
         return self.model(x)
@@ -31,7 +32,11 @@ class Img_2_Img(pl.LightningModule):
         preds = self(images)
         
         loss = self.MSE(preds, labels)
+        psnr = self.psnr(preds, labels)
+        ssim = self.ssim(preds, labels)
         self.log('train_loss', loss, prog_bar=True)
+        self.log("train_psnr", psnr, prog_bar=False)
+        self.log("train_ssim", ssim, prog_bar=True)
 
         return loss
 
@@ -40,7 +45,11 @@ class Img_2_Img(pl.LightningModule):
         preds = self(images)
 
         loss = self.MSE(preds, labels)
+        psnr = self.psnr(preds, labels)
+        ssim = self.ssim(preds, labels)
         self.log('val_loss', loss, prog_bar=True)
+        self.log("val_psnr", psnr, prog_bar=False)
+        self.log("val_ssim", ssim, prog_bar=True)
 
     def test_step(self, test_batch, batch_idx):
         images, labels = test_batch['image'], test_batch['mask']
@@ -73,6 +82,43 @@ class Img_2_Img(pl.LightningModule):
                 "frequency": 1,
             }
         }
+    
+    def on_validation_epoch_end(self):
+        epoch = self.current_epoch
+
+        if (
+            self.example_val_batch is None
+            or epoch % self.log_image_every_n_epochs != 0
+        ):
+            return
+
+        images, labels, preds = self.example_val_batch
+
+        # Take first 8 samples
+        images = images[:8].cpu()
+        labels = labels[:8].cpu()
+        preds  = preds[:8].cpu()
+
+        # Your visualization function
+        show_image_mask_grid(
+            images,
+            preds,  # or labels, depending what you want to show
+            nrow=4,
+            img_name=f"val_pred_epoch_{epoch}"
+        )
+
+        # Optional: W&B logging
+        if isinstance(self.logger, pl.loggers.WandbLogger):
+            import wandb
+            self.logger.experiment.log({
+                "val_examples": wandb.Image(
+                    f"logs/val_pred_epoch_{epoch}.png",
+                    caption=f"Epoch {epoch}"
+                )
+            })
+
+        # Free memory
+        self.example_val_batch = None
 
 if __name__ == '__main__':
     # print('Training UNET model...')
